{"ast":null,"code":"import _classPrivateMethodInitSpec from \"C:/Users/Admin/Desktop/fluent_GJ/frontend/node_modules/@babel/runtime/helpers/esm/classPrivateMethodInitSpec.js\";\nimport _classPrivateFieldInitSpec from \"C:/Users/Admin/Desktop/fluent_GJ/frontend/node_modules/@babel/runtime/helpers/esm/classPrivateFieldInitSpec.js\";\nimport _defineProperty from \"C:/Users/Admin/Desktop/fluent_GJ/frontend/node_modules/@babel/runtime/helpers/esm/defineProperty.js\";\nimport _assertClassBrand from \"C:/Users/Admin/Desktop/fluent_GJ/frontend/node_modules/@babel/runtime/helpers/esm/assertClassBrand.js\";\nimport _classPrivateFieldSet from \"C:/Users/Admin/Desktop/fluent_GJ/frontend/node_modules/@babel/runtime/helpers/esm/classPrivateFieldSet2.js\";\nimport _classPrivateFieldGet from \"C:/Users/Admin/Desktop/fluent_GJ/frontend/node_modules/@babel/runtime/helpers/esm/classPrivateFieldGet2.js\";\n//import { TypedDataDomain, TypedDataField } from \"@ethersproject/providerabstract-signer\";\nimport { getAddress } from \"../address/index.js\";\nimport { keccak256 } from \"../crypto/index.js\";\nimport { recoverAddress } from \"../transaction/index.js\";\nimport { concat, defineProperties, getBigInt, getBytes, hexlify, isHexString, mask, toBeHex, toQuantity, toTwos, zeroPadValue, assertArgument } from \"../utils/index.js\";\nimport { id } from \"./id.js\";\nconst padding = new Uint8Array(32);\npadding.fill(0);\nconst BN__1 = BigInt(-1);\nconst BN_0 = BigInt(0);\nconst BN_1 = BigInt(1);\nconst BN_MAX_UINT256 = BigInt(\"0xffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff\");\n;\n;\nfunction hexPadRight(value) {\n  const bytes = getBytes(value);\n  const padOffset = bytes.length % 32;\n  if (padOffset) {\n    return concat([bytes, padding.slice(padOffset)]);\n  }\n  return hexlify(bytes);\n}\nconst hexTrue = toBeHex(BN_1, 32);\nconst hexFalse = toBeHex(BN_0, 32);\nconst domainFieldTypes = {\n  name: \"string\",\n  version: \"string\",\n  chainId: \"uint256\",\n  verifyingContract: \"address\",\n  salt: \"bytes32\"\n};\nconst domainFieldNames = [\"name\", \"version\", \"chainId\", \"verifyingContract\", \"salt\"];\nfunction checkString(key) {\n  return function (value) {\n    assertArgument(typeof value === \"string\", \"invalid domain value for \".concat(JSON.stringify(key)), \"domain.\".concat(key), value);\n    return value;\n  };\n}\nconst domainChecks = {\n  name: checkString(\"name\"),\n  version: checkString(\"version\"),\n  chainId: function (_value) {\n    const value = getBigInt(_value, \"domain.chainId\");\n    assertArgument(value >= 0, \"invalid chain ID\", \"domain.chainId\", _value);\n    if (Number.isSafeInteger(value)) {\n      return Number(value);\n    }\n    return toQuantity(value);\n  },\n  verifyingContract: function (value) {\n    try {\n      return getAddress(value).toLowerCase();\n    } catch (error) {}\n    assertArgument(false, \"invalid domain value \\\"verifyingContract\\\"\", \"domain.verifyingContract\", value);\n  },\n  salt: function (value) {\n    const bytes = getBytes(value, \"domain.salt\");\n    assertArgument(bytes.length === 32, \"invalid domain value \\\"salt\\\"\", \"domain.salt\", value);\n    return hexlify(bytes);\n  }\n};\nfunction getBaseEncoder(type) {\n  // intXX and uintXX\n  {\n    const match = type.match(/^(u?)int(\\d+)$/);\n    if (match) {\n      const signed = match[1] === \"\";\n      const width = parseInt(match[2]);\n      assertArgument(width % 8 === 0 && width !== 0 && width <= 256 && match[2] === String(width), \"invalid numeric width\", \"type\", type);\n      const boundsUpper = mask(BN_MAX_UINT256, signed ? width - 1 : width);\n      const boundsLower = signed ? (boundsUpper + BN_1) * BN__1 : BN_0;\n      return function (_value) {\n        const value = getBigInt(_value, \"value\");\n        assertArgument(value >= boundsLower && value <= boundsUpper, \"value out-of-bounds for \".concat(type), \"value\", value);\n        return toBeHex(signed ? toTwos(value, 256) : value, 32);\n      };\n    }\n  }\n  // bytesXX\n  {\n    const match = type.match(/^bytes(\\d+)$/);\n    if (match) {\n      const width = parseInt(match[1]);\n      assertArgument(width !== 0 && width <= 32 && match[1] === String(width), \"invalid bytes width\", \"type\", type);\n      return function (value) {\n        const bytes = getBytes(value);\n        assertArgument(bytes.length === width, \"invalid length for \".concat(type), \"value\", value);\n        return hexPadRight(value);\n      };\n    }\n  }\n  switch (type) {\n    case \"address\":\n      return function (value) {\n        return zeroPadValue(getAddress(value), 32);\n      };\n    case \"bool\":\n      return function (value) {\n        return !value ? hexFalse : hexTrue;\n      };\n    case \"bytes\":\n      return function (value) {\n        return keccak256(value);\n      };\n    case \"string\":\n      return function (value) {\n        return id(value);\n      };\n  }\n  return null;\n}\nfunction encodeType(name, fields) {\n  return \"\".concat(name, \"(\").concat(fields.map(_ref => {\n    let {\n      name,\n      type\n    } = _ref;\n    return type + \" \" + name;\n  }).join(\",\"), \")\");\n}\n// foo[][3] => { base: \"foo\", index: \"[][3]\", array: {\n//     base: \"foo\", prefix: \"foo[]\", count: 3 } }\nfunction splitArray(type) {\n  const match = type.match(/^([^\\x5b]*)((\\x5b\\d*\\x5d)*)(\\x5b(\\d*)\\x5d)$/);\n  if (match) {\n    return {\n      base: match[1],\n      index: match[2] + match[4],\n      array: {\n        base: match[1],\n        prefix: match[1] + match[2],\n        count: match[5] ? parseInt(match[5]) : -1\n      }\n    };\n  }\n  return {\n    base: type\n  };\n}\n/**\n *  A **TypedDataEncode** prepares and encodes [[link-eip-712]] payloads\n *  for signed typed data.\n *\n *  This is useful for those that wish to compute various components of a\n *  typed data hash, primary types, or sub-components, but generally the\n *  higher level [[Signer-signTypedData]] is more useful.\n */\nvar _types2 = /*#__PURE__*/new WeakMap();\nvar _fullTypes = /*#__PURE__*/new WeakMap();\nvar _encoderCache = /*#__PURE__*/new WeakMap();\nvar _TypedDataEncoder_brand = /*#__PURE__*/new WeakSet();\nexport class TypedDataEncoder {\n  /**\n   *  The types.\n   */\n  get types() {\n    return JSON.parse(_classPrivateFieldGet(_types2, this));\n  }\n  /**\n   *  Create a new **TypedDataEncoder** for %%types%%.\n   *\n   *  This performs all necessary checking that types are valid and\n   *  do not violate the [[link-eip-712]] structural constraints as\n   *  well as computes the [[primaryType]].\n   */\n  constructor(_types) {\n    _classPrivateMethodInitSpec(this, _TypedDataEncoder_brand);\n    /**\n     *  The primary type for the structured [[types]].\n     *\n     *  This is derived automatically from the [[types]], since no\n     *  recursion is possible, once the DAG for the types is consturcted\n     *  internally, the primary type must be the only remaining type with\n     *  no parent nodes.\n     */\n    _defineProperty(this, \"primaryType\", void 0);\n    _classPrivateFieldInitSpec(this, _types2, void 0);\n    _classPrivateFieldInitSpec(this, _fullTypes, void 0);\n    _classPrivateFieldInitSpec(this, _encoderCache, void 0);\n    _classPrivateFieldSet(_fullTypes, this, new Map());\n    _classPrivateFieldSet(_encoderCache, this, new Map());\n    // Link struct types to their direct child structs\n    const links = new Map();\n    // Link structs to structs which contain them as a child\n    const parents = new Map();\n    // Link all subtypes within a given struct\n    const subtypes = new Map();\n    const types = {};\n    Object.keys(_types).forEach(type => {\n      types[type] = _types[type].map(_ref2 => {\n        let {\n          name,\n          type\n        } = _ref2;\n        // Normalize the base type (unless name conflict)\n        let {\n          base,\n          index\n        } = splitArray(type);\n        if (base === \"int\" && !_types[\"int\"]) {\n          base = \"int256\";\n        }\n        if (base === \"uint\" && !_types[\"uint\"]) {\n          base = \"uint256\";\n        }\n        return {\n          name,\n          type: base + (index || \"\")\n        };\n      });\n      links.set(type, new Set());\n      parents.set(type, []);\n      subtypes.set(type, new Set());\n    });\n    _classPrivateFieldSet(_types2, this, JSON.stringify(types));\n    for (const name in types) {\n      const uniqueNames = new Set();\n      for (const field of types[name]) {\n        // Check each field has a unique name\n        assertArgument(!uniqueNames.has(field.name), \"duplicate variable name \".concat(JSON.stringify(field.name), \" in \").concat(JSON.stringify(name)), \"types\", _types);\n        uniqueNames.add(field.name);\n        // Get the base type (drop any array specifiers)\n        const baseType = splitArray(field.type).base;\n        assertArgument(baseType !== name, \"circular type reference to \".concat(JSON.stringify(baseType)), \"types\", _types);\n        // Is this a base encoding type?\n        const encoder = getBaseEncoder(baseType);\n        if (encoder) {\n          continue;\n        }\n        assertArgument(parents.has(baseType), \"unknown type \".concat(JSON.stringify(baseType)), \"types\", _types);\n        // Add linkage\n        parents.get(baseType).push(name);\n        links.get(name).add(baseType);\n      }\n    }\n    // Deduce the primary type\n    const primaryTypes = Array.from(parents.keys()).filter(n => parents.get(n).length === 0);\n    assertArgument(primaryTypes.length !== 0, \"missing primary type\", \"types\", _types);\n    assertArgument(primaryTypes.length === 1, \"ambiguous primary types or unused types: \".concat(primaryTypes.map(t => JSON.stringify(t)).join(\", \")), \"types\", _types);\n    defineProperties(this, {\n      primaryType: primaryTypes[0]\n    });\n    // Check for circular type references\n    function checkCircular(type, found) {\n      assertArgument(!found.has(type), \"circular type reference to \".concat(JSON.stringify(type)), \"types\", _types);\n      found.add(type);\n      for (const child of links.get(type)) {\n        if (!parents.has(child)) {\n          continue;\n        }\n        // Recursively check children\n        checkCircular(child, found);\n        // Mark all ancestors as having this decendant\n        for (const subtype of found) {\n          subtypes.get(subtype).add(child);\n        }\n      }\n      found.delete(type);\n    }\n    checkCircular(this.primaryType, new Set());\n    // Compute each fully describe type\n    for (const [name, set] of subtypes) {\n      const st = Array.from(set);\n      st.sort();\n      _classPrivateFieldGet(_fullTypes, this).set(name, encodeType(name, types[name]) + st.map(t => encodeType(t, types[t])).join(\"\"));\n    }\n  }\n  /**\n   *  Returnthe encoder for the specific %%type%%.\n   */\n  getEncoder(type) {\n    let encoder = _classPrivateFieldGet(_encoderCache, this).get(type);\n    if (!encoder) {\n      encoder = _assertClassBrand(_TypedDataEncoder_brand, this, _getEncoder).call(this, type);\n      _classPrivateFieldGet(_encoderCache, this).set(type, encoder);\n    }\n    return encoder;\n  }\n  /**\n   *  Return the full type for %%name%%.\n   */\n  encodeType(name) {\n    const result = _classPrivateFieldGet(_fullTypes, this).get(name);\n    assertArgument(result, \"unknown type: \".concat(JSON.stringify(name)), \"name\", name);\n    return result;\n  }\n  /**\n   *  Return the encoded %%value%% for the %%type%%.\n   */\n  encodeData(type, value) {\n    return this.getEncoder(type)(value);\n  }\n  /**\n   *  Returns the hash of %%value%% for the type of %%name%%.\n   */\n  hashStruct(name, value) {\n    return keccak256(this.encodeData(name, value));\n  }\n  /**\n   *  Return the fulled encoded %%value%% for the [[types]].\n   */\n  encode(value) {\n    return this.encodeData(this.primaryType, value);\n  }\n  /**\n   *  Return the hash of the fully encoded %%value%% for the [[types]].\n   */\n  hash(value) {\n    return this.hashStruct(this.primaryType, value);\n  }\n  /**\n   *  @_ignore:\n   */\n  _visit(type, value, callback) {\n    // Basic encoder type (address, bool, uint256, etc)\n    {\n      const encoder = getBaseEncoder(type);\n      if (encoder) {\n        return callback(type, value);\n      }\n    }\n    // Array\n    const array = splitArray(type).array;\n    if (array) {\n      assertArgument(array.count === -1 || array.count === value.length, \"array length mismatch; expected length \".concat(array.count), \"value\", value);\n      return value.map(v => this._visit(array.prefix, v, callback));\n    }\n    // Struct\n    const fields = this.types[type];\n    if (fields) {\n      return fields.reduce((accum, _ref3) => {\n        let {\n          name,\n          type\n        } = _ref3;\n        accum[name] = this._visit(type, value[name], callback);\n        return accum;\n      }, {});\n    }\n    assertArgument(false, \"unknown type: \".concat(type), \"type\", type);\n  }\n  /**\n   *  Call %%calback%% for each value in %%value%%, passing the type and\n   *  component within %%value%%.\n   *\n   *  This is useful for replacing addresses or other transformation that\n   *  may be desired on each component, based on its type.\n   */\n  visit(value, callback) {\n    return this._visit(this.primaryType, value, callback);\n  }\n  /**\n   *  Create a new **TypedDataEncoder** for %%types%%.\n   */\n  static from(types) {\n    return new TypedDataEncoder(types);\n  }\n  /**\n   *  Return the primary type for %%types%%.\n   */\n  static getPrimaryType(types) {\n    return TypedDataEncoder.from(types).primaryType;\n  }\n  /**\n   *  Return the hashed struct for %%value%% using %%types%% and %%name%%.\n   */\n  static hashStruct(name, types, value) {\n    return TypedDataEncoder.from(types).hashStruct(name, value);\n  }\n  /**\n   *  Return the domain hash for %%domain%%.\n   */\n  static hashDomain(domain) {\n    const domainFields = [];\n    for (const name in domain) {\n      if (domain[name] == null) {\n        continue;\n      }\n      const type = domainFieldTypes[name];\n      assertArgument(type, \"invalid typed-data domain key: \".concat(JSON.stringify(name)), \"domain\", domain);\n      domainFields.push({\n        name,\n        type\n      });\n    }\n    domainFields.sort((a, b) => {\n      return domainFieldNames.indexOf(a.name) - domainFieldNames.indexOf(b.name);\n    });\n    return TypedDataEncoder.hashStruct(\"EIP712Domain\", {\n      EIP712Domain: domainFields\n    }, domain);\n  }\n  /**\n   *  Return the fully encoded [[link-eip-712]] %%value%% for %%types%% with %%domain%%.\n   */\n  static encode(domain, types, value) {\n    return concat([\"0x1901\", TypedDataEncoder.hashDomain(domain), TypedDataEncoder.from(types).hash(value)]);\n  }\n  /**\n   *  Return the hash of the fully encoded [[link-eip-712]] %%value%% for %%types%% with %%domain%%.\n   */\n  static hash(domain, types, value) {\n    return keccak256(TypedDataEncoder.encode(domain, types, value));\n  }\n  // Replaces all address types with ENS names with their looked up address\n  /**\n   * Resolves to the value from resolving all addresses in %%value%% for\n   * %%types%% and the %%domain%%.\n   */\n  static async resolveNames(domain, types, value, resolveName) {\n    // Make a copy to isolate it from the object passed in\n    domain = Object.assign({}, domain);\n    // Allow passing null to ignore value\n    for (const key in domain) {\n      if (domain[key] == null) {\n        delete domain[key];\n      }\n    }\n    // Look up all ENS names\n    const ensCache = {};\n    // Do we need to look up the domain's verifyingContract?\n    if (domain.verifyingContract && !isHexString(domain.verifyingContract, 20)) {\n      ensCache[domain.verifyingContract] = \"0x\";\n    }\n    // We are going to use the encoder to visit all the base values\n    const encoder = TypedDataEncoder.from(types);\n    // Get a list of all the addresses\n    encoder.visit(value, (type, value) => {\n      if (type === \"address\" && !isHexString(value, 20)) {\n        ensCache[value] = \"0x\";\n      }\n      return value;\n    });\n    // Lookup each name\n    for (const name in ensCache) {\n      ensCache[name] = await resolveName(name);\n    }\n    // Replace the domain verifyingContract if needed\n    if (domain.verifyingContract && ensCache[domain.verifyingContract]) {\n      domain.verifyingContract = ensCache[domain.verifyingContract];\n    }\n    // Replace all ENS names with their address\n    value = encoder.visit(value, (type, value) => {\n      if (type === \"address\" && ensCache[value]) {\n        return ensCache[value];\n      }\n      return value;\n    });\n    return {\n      domain,\n      value\n    };\n  }\n  /**\n   *  Returns the JSON-encoded payload expected by nodes which implement\n   *  the JSON-RPC [[link-eip-712]] method.\n   */\n  static getPayload(domain, types, value) {\n    // Validate the domain fields\n    TypedDataEncoder.hashDomain(domain);\n    // Derive the EIP712Domain Struct reference type\n    const domainValues = {};\n    const domainTypes = [];\n    domainFieldNames.forEach(name => {\n      const value = domain[name];\n      if (value == null) {\n        return;\n      }\n      domainValues[name] = domainChecks[name](value);\n      domainTypes.push({\n        name,\n        type: domainFieldTypes[name]\n      });\n    });\n    const encoder = TypedDataEncoder.from(types);\n    // Get the normalized types\n    types = encoder.types;\n    const typesWithDomain = Object.assign({}, types);\n    assertArgument(typesWithDomain.EIP712Domain == null, \"types must not contain EIP712Domain type\", \"types.EIP712Domain\", types);\n    typesWithDomain.EIP712Domain = domainTypes;\n    // Validate the data structures and types\n    encoder.encode(value);\n    return {\n      types: typesWithDomain,\n      domain: domainValues,\n      primaryType: encoder.primaryType,\n      message: encoder.visit(value, (type, value) => {\n        // bytes\n        if (type.match(/^bytes(\\d*)/)) {\n          return hexlify(getBytes(value));\n        }\n        // uint or int\n        if (type.match(/^u?int/)) {\n          return getBigInt(value).toString();\n        }\n        switch (type) {\n          case \"address\":\n            return value.toLowerCase();\n          case \"bool\":\n            return !!value;\n          case \"string\":\n            assertArgument(typeof value === \"string\", \"invalid string\", \"value\", value);\n            return value;\n        }\n        assertArgument(false, \"unsupported type\", \"type\", type);\n      })\n    };\n  }\n}\n/**\n *  Compute the address used to sign the typed data for the %%signature%%.\n */\nfunction _getEncoder(type) {\n  // Basic encoder type (address, bool, uint256, etc)\n  {\n    const encoder = getBaseEncoder(type);\n    if (encoder) {\n      return encoder;\n    }\n  }\n  // Array\n  const array = splitArray(type).array;\n  if (array) {\n    const subtype = array.prefix;\n    const subEncoder = this.getEncoder(subtype);\n    return value => {\n      assertArgument(array.count === -1 || array.count === value.length, \"array length mismatch; expected length \".concat(array.count), \"value\", value);\n      let result = value.map(subEncoder);\n      if (_classPrivateFieldGet(_fullTypes, this).has(subtype)) {\n        result = result.map(keccak256);\n      }\n      return keccak256(concat(result));\n    };\n  }\n  // Struct\n  const fields = this.types[type];\n  if (fields) {\n    const encodedType = id(_classPrivateFieldGet(_fullTypes, this).get(type));\n    return value => {\n      const values = fields.map(_ref4 => {\n        let {\n          name,\n          type\n        } = _ref4;\n        const result = this.getEncoder(type)(value[name]);\n        if (_classPrivateFieldGet(_fullTypes, this).has(type)) {\n          return keccak256(result);\n        }\n        return result;\n      });\n      values.unshift(encodedType);\n      return concat(values);\n    };\n  }\n  assertArgument(false, \"unknown type: \".concat(type), \"type\", type);\n}\nexport function verifyTypedData(domain, types, value, signature) {\n  return recoverAddress(TypedDataEncoder.hash(domain, types, value), signature);\n}\n//# sourceMappingURL=typed-data.js.map","map":null,"metadata":{},"sourceType":"module","externalDependencies":[]}